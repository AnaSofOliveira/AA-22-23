{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1 1 1 3 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 4 3 3 1 1 1 1 1 2 2]\n",
      "0 and 1\n",
      "1 are 3\n",
      "2 be 1\n",
      "3 better 1\n",
      "4 cause 1\n",
      "5 changing 3\n",
      "6 for 2\n",
      "7 it 1\n",
      "8 later 1\n",
      "9 like 1\n",
      "10 ll 2\n",
      "11 loser 1\n",
      "12 now 1\n",
      "13 or 1\n",
      "14 rattle 1\n",
      "15 shake 1\n",
      "16 sink 1\n",
      "17 soon 1\n",
      "18 start 1\n",
      "19 stone 1\n",
      "20 swimming 1\n",
      "21 the 4\n",
      "22 they 3\n",
      "23 times 3\n",
      "24 to 1\n",
      "25 walls 1\n",
      "26 will 1\n",
      "27 win 1\n",
      "28 windows 1\n",
      "29 you 2\n",
      "30 your 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "corpus = [ \"you better start swimming or you’ll sink like a stone for the times they are a-changing\", \n",
    "            \"the loser now will be later to win cause the times they are a-changing\", \n",
    "            \"it’ll soon shake your windows and rattle your walls for the times they are a-changing\"]\n",
    "\n",
    "cv = CountVectorizer().fit(corpus)\n",
    "Vocab = cv.vocabulary_\n",
    "\n",
    "#print(Vocab)\n",
    "\n",
    "wordSort = cv.get_feature_names_out()\n",
    "\n",
    "# Ordenar vocabulário por ordem de ocorrencia\n",
    "voc = {k: v for k,v in sorted(Vocab.items(), key=lambda item: item[1])}\n",
    "#print(voc)\n",
    "\n",
    "# Trocar a chave pelo indice\n",
    "voc2 = {value: key for key, value in voc.items()}\n",
    "#print(voc2)\n",
    "\n",
    "\n",
    "X = cv.transform(corpus)\n",
    "# Não convém fazer no caso dos dados IMDB\n",
    "X = X.toarray()\n",
    "#print(X.shape) # 3 documentos X 31 palavras\n",
    "\n",
    "\n",
    "\n",
    "# Quantas vezes cada palavra aparece nos documentos todos\n",
    "count = np.sum(X, axis=0)\n",
    "print(count)\n",
    "\n",
    "for i in range(31): \n",
    "    print(i, voc2[i], count[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer \n",
    "- Agarra no resultado do CountVectorizer (Matriz de contagens) e normaliza, de forma a que os vetores tenham norma 1 e que as palavras que aparecem em poucos documentos tenham um maior peso que as palavras que aparecem em muitos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.15841025 0.         0.26821186 0.         0.15841025\n",
      "  0.20398203 0.         0.         0.26821186 0.20398203 0.\n",
      "  0.         0.26821186 0.         0.         0.26821186 0.\n",
      "  0.26821186 0.26821186 0.26821186 0.15841025 0.15841025 0.15841025\n",
      "  0.         0.         0.         0.         0.         0.53642372\n",
      "  0.        ]\n",
      " [0.         0.17979686 0.30442255 0.         0.30442255 0.17979686\n",
      "  0.         0.         0.30442255 0.         0.         0.30442255\n",
      "  0.30442255 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.35959372 0.17979686 0.17979686\n",
      "  0.30442255 0.         0.30442255 0.30442255 0.         0.\n",
      "  0.        ]\n",
      " [0.26821186 0.15841025 0.         0.         0.         0.15841025\n",
      "  0.20398203 0.26821186 0.         0.         0.20398203 0.\n",
      "  0.         0.         0.26821186 0.26821186 0.         0.26821186\n",
      "  0.         0.         0.         0.15841025 0.15841025 0.15841025\n",
      "  0.         0.26821186 0.         0.         0.26821186 0.\n",
      "  0.53642372]]\n"
     ]
    }
   ],
   "source": [
    "## Podemos aplicar com os resultados do CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "cv = CountVectorizer().fit(corpus)\n",
    "X = cv.transform(corpus)\n",
    "\n",
    "tfidf = TfidfTransformer().fit(X)\n",
    "Y = tfidf.transform(X)\n",
    "\n",
    "print(Y.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you better start swimming or you’ll sink like a stone for the times they are a-changing', 'the loser now will be later to win cause the times they are a-changing', 'it’ll soon shake your windows and rattle your walls for the times they are a-changing']\n",
      "[[0.         0.15841025 0.         0.26821186 0.         0.15841025\n",
      "  0.20398203 0.         0.         0.26821186 0.20398203 0.\n",
      "  0.         0.26821186 0.         0.         0.26821186 0.\n",
      "  0.26821186 0.26821186 0.26821186 0.15841025 0.15841025 0.15841025\n",
      "  0.         0.         0.         0.         0.         0.53642372\n",
      "  0.        ]\n",
      " [0.         0.17979686 0.30442255 0.         0.30442255 0.17979686\n",
      "  0.         0.         0.30442255 0.         0.         0.30442255\n",
      "  0.30442255 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.35959372 0.17979686 0.17979686\n",
      "  0.30442255 0.         0.30442255 0.30442255 0.         0.\n",
      "  0.        ]\n",
      " [0.26821186 0.15841025 0.         0.         0.         0.15841025\n",
      "  0.20398203 0.26821186 0.         0.         0.20398203 0.\n",
      "  0.         0.         0.26821186 0.26821186 0.         0.26821186\n",
      "  0.         0.         0.         0.15841025 0.15841025 0.15841025\n",
      "  0.         0.26821186 0.         0.         0.26821186 0.\n",
      "  0.53642372]]\n"
     ]
    }
   ],
   "source": [
    "## Ou podemos aplicar o TfidfVectorizer diretamente com o corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(corpus)\n",
    "tfidf = TfidfVectorizer().fit(corpus)\n",
    "Y = tfidf.transform(corpus)\n",
    "\n",
    "print(Y.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\xef'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mAnaSofOliveira\\AA-22-23\\Laboratorios\\LabTexto\\labTexto.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22646576656c6f706d656e74227d7d/AnaSofOliveira/AA-22-23/Laboratorios/LabTexto/labTexto.ipynb#X13sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22646576656c6f706d656e74227d7d/AnaSofOliveira/AA-22-23/Laboratorios/LabTexto/labTexto.ipynb#X13sdnNjb2RlLXZmcw%3D%3D?line=2'>3</a>\u001b[0m fN \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/anaso/Documents/AA/AA-22-23/Laboratorios/LabTexto/Material fornecido/imdbCriticas.p\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22646576656c6f706d656e74227d7d/AnaSofOliveira/AA-22-23/Laboratorios/LabTexto/labTexto.ipynb#X13sdnNjb2RlLXZmcw%3D%3D?line=4'>5</a>\u001b[0m D \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(fN, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '\\xef'."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "fN = '/Users/anaso/Documents/AA/AA-22-23/Laboratorios/LabTexto/Material fornecido/imdbCriticas.p'\n",
    "\n",
    "D = pickle.load(open(fN, 'rb'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b40f68814b93475b29075cb0adeb1712a4387a9e06914676246b503f1ae483b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
