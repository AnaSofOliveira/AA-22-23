{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalho Prático Apredizagem Automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anaso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\anaso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import mglearn\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(critica): \n",
    "    critica = critica.replace(\"<br />\", \" \")\n",
    "    critica = re.sub(r'[^a-zA-Z]+', ' ', critica.lower())\n",
    "    return critica\n",
    "\n",
    "def stop_words(critica): \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    no_stop_words = \" \".join((palavra if palavra not in stop_words else \" \") for palavra in critica.split()) \n",
    "    return no_stop_words\n",
    "\n",
    "def lematizacao(critica, lemma=WordNetLemmatizer()): \n",
    "    lemma = \" \".join((lemma.lemmatize(palavra)) for palavra in critica.split())\n",
    "    return lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vector(corpus, tfidf=TfidfVectorizer(), treino=True):\n",
    "\n",
    "    docs = [limpeza(texto) for texto in corpus]\n",
    "    docs = [stop_words(texto) for texto in docs] \n",
    "    docs = [lematizacao(texto) for texto in docs]\n",
    "\n",
    "    if(treino):\n",
    "        modelo = tfidf.fit(docs)\n",
    "        Dict = {'tfidf_model': modelo}\n",
    "        pickle.dump(Dict, open('models/tfidf.p', 'wb'))\n",
    "        \n",
    "    else:\n",
    "        Dict = pickle.load(open('models/tfidf.p', 'rb'))\n",
    "        tfidf = Dict['tfidf_model']\n",
    "\n",
    "    return tfidf.transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binClassify(X, y, model='LogisticRegression', treino=True):\n",
    "\n",
    "    if(len(np.unique(y))>2):\n",
    "        raise ValueError(\"Targets errados. \")\n",
    "    \n",
    "    else:\n",
    "        modelos = {\n",
    "            \"LogisticRegression\": LogisticRegression(), \n",
    "            \"RandomForestClassifier\": RandomForestClassifier(), \n",
    "            \"SupportVectorMachines\": SVC()\n",
    "        }    \n",
    "\n",
    "        modelo = modelos.get(model)\n",
    "\n",
    "        if(treino and y.all()!=None): \n",
    "            modelo = modelo.fit(X, y)\n",
    "            Dict = {model: modelo}\n",
    "            pickle.dump(Dict, open('models/'+model+'.p', 'wb'))\n",
    "\n",
    "        elif(not treino):\n",
    "            Dict = pickle.load(open('models/'+model+'.p', 'rb'))\n",
    "            modelo = Dict[model]\n",
    "        \n",
    "        return modelo.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClassify(X, y=None, model='LogisticRegression', treino=True):\n",
    "\n",
    "    if(len(np.unique(y))<=2):\n",
    "        raise ValueError(\"Targets errados. \")\n",
    "    \n",
    "    else:\n",
    "        modelos = {\n",
    "            \"LogisticRegression\": LogisticRegression(max_iter=10000), \n",
    "            \"RandomForestClassifier\": RandomForestClassifier(), \n",
    "            \"SupportVectorMachines\": SVC()\n",
    "        }    \n",
    "\n",
    "        modelo = modelos.get(model)\n",
    "        \n",
    "        if(treino and y.all()!=None): \n",
    "            modelo = modelo.fit(X, y)\n",
    "            Dict = {model: modelo}\n",
    "            pickle.dump(Dict, open('models/'+model+'.p', 'wb'))\n",
    "\n",
    "        elif(not treino):\n",
    "            Dict = pickle.load(open('models/'+model+'.p', 'rb'))\n",
    "            modelo = Dict[model]\n",
    "        \n",
    "        return modelo.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pickle.load(open(\"/Users/anaso/Documents/AA/AA-22-23/Trabalho Final/imdbFull.p\", 'rb'))\n",
    "\n",
    "corpus = D.data\n",
    "y = D.target\n",
    "\n",
    "yb = [1 if val>5 else 0 for val in y]\n",
    "\n",
    "X = text2vector(corpus, tfidf=TfidfVectorizer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin = binClassify(X, yb, treino=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi = multiClassify(X, y, treino=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23067  1933]\n",
      " [ 1496 23504]]\n",
      "[[9249  113  196  225   35   65   15  224]\n",
      " [1851 1643  326  414   52   73   18  209]\n",
      " [1224  114 2667  463  106   92   33  262]\n",
      " [ 846   79  280 3467  143  173   43  300]\n",
      " [ 178   24  100  245 2696  546  123  891]\n",
      " [ 145   16   64  126  260 3631  152 1465]\n",
      " [ 124   10   30   73  259  558 1666 1887]\n",
      " [ 202   14   46   70  182  387  105 8725]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yb, y_bin))\n",
    "print(confusion_matrix(y, y_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     25000\n",
      "           1       0.92      0.94      0.93     25000\n",
      "\n",
      "    accuracy                           0.93     50000\n",
      "   macro avg       0.93      0.93      0.93     50000\n",
      "weighted avg       0.93      0.93      0.93     50000\n",
      "\n",
      "_______________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.91      0.77     10122\n",
      "           2       0.82      0.36      0.50      4586\n",
      "           3       0.72      0.54      0.62      4961\n",
      "           4       0.68      0.65      0.67      5331\n",
      "           7       0.72      0.56      0.63      4803\n",
      "           8       0.66      0.62      0.64      5859\n",
      "           9       0.77      0.36      0.49      4607\n",
      "          10       0.62      0.90      0.74      9731\n",
      "\n",
      "    accuracy                           0.67     50000\n",
      "   macro avg       0.71      0.61      0.63     50000\n",
      "weighted avg       0.69      0.67      0.66     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yb, y_bin))\n",
    "print(\"_______________\")\n",
    "print(classification_report(y, y_multi))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclasse\n",
    "texto_treino, texto_teste, y_treino, y_teste = train_test_split(corpus, y, train_size=0.5, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = text2vector(texto_treino, treino=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_treino = multiClassify(X1, y_treino, treino=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4765   25   57   69   19   16    9  101]\n",
      " [ 895  968   88  162   19   32    4  125]\n",
      " [ 607   35 1478  134   44   36   13  133]\n",
      " [ 410   19   61 1906   49   68   13  139]\n",
      " [ 107    8   28   75 1553  153   26  452]\n",
      " [  87    5   21   36   94 1992   36  659]\n",
      " [  72    6   12   23   85  219  995  891]\n",
      " [ 108    4   13   25   61  135   30 4490]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.94      0.79      5061\n",
      "           2       0.90      0.42      0.58      2293\n",
      "           3       0.84      0.60      0.70      2480\n",
      "           4       0.78      0.72      0.75      2665\n",
      "           7       0.81      0.65      0.72      2402\n",
      "           8       0.75      0.68      0.71      2930\n",
      "           9       0.88      0.43      0.58      2303\n",
      "          10       0.64      0.92      0.76      4866\n",
      "\n",
      "    accuracy                           0.73     25000\n",
      "   macro avg       0.79      0.67      0.70     25000\n",
      "weighted avg       0.76      0.73      0.71     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_treino, y_multi_treino))\n",
    "print(classification_report(y_treino, y_multi_treino))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = text2vector(texto_teste, treino=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_teste = multiClassify(X2, y_teste, treino=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4158  151  202  225   30   56   11  228]\n",
      " [1292  147  249  343   38   63    7  154]\n",
      " [ 982  152  393  516   98   97   22  221]\n",
      " [ 669   96  350  828  202  224   31  266]\n",
      " [ 141   18   72  215  518  654  104  679]\n",
      " [ 126   19   44  129  402  748  166 1295]\n",
      " [  81    8   19   63  172  422  140 1399]\n",
      " [ 217   15   28   71  149  456  161 3768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.82      0.65      5061\n",
      "           2       0.24      0.06      0.10      2293\n",
      "           3       0.29      0.16      0.20      2481\n",
      "           4       0.35      0.31      0.33      2666\n",
      "           7       0.32      0.22      0.26      2401\n",
      "           8       0.28      0.26      0.26      2929\n",
      "           9       0.22      0.06      0.10      2304\n",
      "          10       0.47      0.77      0.59      4865\n",
      "\n",
      "    accuracy                           0.43     25000\n",
      "   macro avg       0.34      0.33      0.31     25000\n",
      "weighted avg       0.37      0.43      0.38     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste, y_multi_teste))\n",
    "print(classification_report(y_teste, y_multi_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: \n",
      "Treino: \n",
      "[[5061    0    0    0    0    0    0    0]\n",
      " [   0 2293    0    0    0    0    0    0]\n",
      " [   0    0 2480    0    0    0    0    0]\n",
      " [   0    0    1 2664    0    0    0    0]\n",
      " [   0    0    0    0 2402    0    0    0]\n",
      " [   0    0    0    0    0 2929    0    1]\n",
      " [   0    0    0    0    0    0 2303    0]\n",
      " [   0    0    0    0    0    0    0 4866]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      5061\n",
      "           2       1.00      1.00      1.00      2293\n",
      "           3       1.00      1.00      1.00      2480\n",
      "           4       1.00      1.00      1.00      2665\n",
      "           7       1.00      1.00      1.00      2402\n",
      "           8       1.00      1.00      1.00      2930\n",
      "           9       1.00      1.00      1.00      2303\n",
      "          10       1.00      1.00      1.00      4866\n",
      "\n",
      "    accuracy                           1.00     25000\n",
      "   macro avg       1.00      1.00      1.00     25000\n",
      "weighted avg       1.00      1.00      1.00     25000\n",
      "\n",
      "Teste:\n",
      "[[4530    3    9   31   10   29    2  447]\n",
      " [1815   34   14   48    7   16    1  358]\n",
      " [1703    9   69   86   20   47    2  545]\n",
      " [1524   11   48  174   42  104    6  757]\n",
      " [ 513    0   21   68  124  224    8 1443]\n",
      " [ 482    2    7   55   54  241    6 2082]\n",
      " [ 292    0    4   17   35  112   23 1821]\n",
      " [ 510    1    3   17   41  133    5 4155]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.90      0.55      5061\n",
      "           2       0.57      0.01      0.03      2293\n",
      "           3       0.39      0.03      0.05      2481\n",
      "           4       0.35      0.07      0.11      2666\n",
      "           7       0.37      0.05      0.09      2401\n",
      "           8       0.27      0.08      0.13      2929\n",
      "           9       0.43      0.01      0.02      2304\n",
      "          10       0.36      0.85      0.50      4865\n",
      "\n",
      "    accuracy                           0.37     25000\n",
      "   macro avg       0.39      0.25      0.19     25000\n",
      "weighted avg       0.39      0.37      0.25     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_multi_treino = multiClassify(X1, y_treino, model=\"RandomForestClassifier\", treino=True)\n",
    "y_multi_teste = multiClassify(X2, y_teste, model=\"RandomForestClassifier\", treino=False)\n",
    "\n",
    "print(\"Random Forest Classifier: \")\n",
    "print(\"Treino: \")\n",
    "print(confusion_matrix(y_treino, y_multi_treino))\n",
    "print(classification_report(y_treino, y_multi_treino))\n",
    "\n",
    "print(\"Teste:\")\n",
    "print(confusion_matrix(y_teste, y_multi_teste))\n",
    "print(classification_report(y_teste, y_multi_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "SVC()\n",
      "Support Vector Machines (SVM): \n",
      "Treino: \n",
      "[[5042    0    2    3    1    1    0   12]\n",
      " [ 244 2025    2    7    1    3    1   10]\n",
      " [ 129    0 2325   11    4    1    0   10]\n",
      " [  83    0    0 2560    2    5    0   15]\n",
      " [  17    0    0    6 2279   12    1   87]\n",
      " [  12    0    1    2    2 2785    0  128]\n",
      " [  19    1    2    1   11   41 1986  242]\n",
      " [  17    0    1    1    2    4    0 4841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95      5061\n",
      "           2       1.00      0.88      0.94      2293\n",
      "           3       1.00      0.94      0.97      2480\n",
      "           4       0.99      0.96      0.97      2665\n",
      "           7       0.99      0.95      0.97      2402\n",
      "           8       0.98      0.95      0.96      2930\n",
      "           9       1.00      0.86      0.93      2303\n",
      "          10       0.91      0.99      0.95      4866\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.97      0.94      0.95     25000\n",
      "weighted avg       0.96      0.95      0.95     25000\n",
      "\n",
      "Teste:\n",
      "[[4341   11  124  256   16   49    2  262]\n",
      " [1484   43  179  340   24   52    0  171]\n",
      " [1181   19  277  578   71  103    2  250]\n",
      " [ 803   15  232  927  140  207    2  340]\n",
      " [ 148    0   51  230  418  732   16  806]\n",
      " [ 128    5   29  138  300  766   32 1531]\n",
      " [ 100    1   15   62  118  406   31 1571]\n",
      " [ 231    3   16   68   97  415   28 4007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.86      0.64      5061\n",
      "           2       0.44      0.02      0.04      2293\n",
      "           3       0.30      0.11      0.16      2481\n",
      "           4       0.36      0.35      0.35      2666\n",
      "           7       0.35      0.17      0.23      2401\n",
      "           8       0.28      0.26      0.27      2929\n",
      "           9       0.27      0.01      0.03      2304\n",
      "          10       0.45      0.82      0.58      4865\n",
      "\n",
      "    accuracy                           0.43     25000\n",
      "   macro avg       0.37      0.33      0.29     25000\n",
      "weighted avg       0.39      0.43      0.36     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_multi_treino = multiClassify(X1, y_treino, model=\"SupportVectorMachines\", treino=True)\n",
    "y_multi_teste = multiClassify(X2, y_teste, model=\"SupportVectorMachines\", treino=False)\n",
    "\n",
    "print(\"Support Vector Machines (SVM): \")\n",
    "print(\"Treino: \")\n",
    "print(confusion_matrix(y_treino, y_multi_treino))\n",
    "print(classification_report(y_treino, y_multi_treino))\n",
    "\n",
    "print(\"Teste:\")\n",
    "print(confusion_matrix(y_teste, y_multi_teste))\n",
    "print(classification_report(y_teste, y_multi_teste))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b40f68814b93475b29075cb0adeb1712a4387a9e06914676246b503f1ae483b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
